---
title: "Notes: Statistics for Genomic Data Science (2)"
author: "Kiara"
date: "2025-05-02"
output: md_document
---

Course link: <https://www.coursera.org/learn/statistical-genomics?specialization=genomic-data-science>

Continued from Module 3. 

## Statistical inference 

![The central dogma of statistical inference](https://freeimghost.net/images/2025/05/05/Screenshot-2025-05-05-at-14.14.37.png)

### Comparing model fits under H0/Ha hypotheses and the F-statistic

As described earlier (in part 1 notes), the model can originally be expressed as Y = b0 + b1P + b2B + e. This is still the case for Ha, whereas under H0, we can simplify it to Y = b0 + b2B + e, since **under H0 we assume that there's no relationship between the primary variables** (eg. phenotype, represented by 'P' in the expression) **and the data**. 

Now we want to ask, **which model fits better, the one under H0 or the one under Ha?** Again, this involves optimizing/minimizing overall error norm. We have the **F-statistic to compare the goodness-of-fit of the two models**:

![F-stat](https://freeimghost.net/images/2025/05/04/Screenshot-2025-05-05-at-07.30.51.png)

RSS is just the *residual sum of squares* (i.e. the sum of squared L2 norm of errors). RSS<sub>0</sub>: RSS under H0; RSS<sub>1</sub>: RSS under Ha. 

The standardization allows us to come up with a standard form for the distribution of F-statistic, just like we're standardizing to SD units for the t-stat.

**A large F-statistic suggests that Ha fits significantly better than H0.**

### Calculating test statistics in R

The `genefilter` package lets us compute statistics rapidly for very simple cases.
```{r}
library(Biobase)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bottomly_eset.RData")
load(file=con)
close(con)
bot = bottomly.eset
pdata=pData(bot)
edata=as.matrix(exprs(bot))
fdata = fData(bot)

# Transform and filter the data 
edata = log2(as.matrix(edata) + 1)
edata = edata[rowMeans(edata) > 10, ]

library(genefilter)
# t-statistic for two-group comparisons
table(pdata$strain)
tstats_obj = rowttests(edata,pdata$strain)
names(tstats_obj)
hist(tstats_obj$statistic,col=2)

# F-statistic for multi-group comparisons (the variable has multiple levels)
table(pdata$lane.number)
fstats_obj = rowFtests(edata,as.factor(pdata$lane.number))
names(fstats_obj)
hist(fstats_obj$statistic,col=2)

```

We can use model-fitting in `limma` and then get the moderated statistics (we mentioned this in Course 5!! models like `limma` and `DESeq2` leverage the '*borrowing info across genes*' to stabilize variance estimates for individual features/genes~~), which is a bit different from that (unmoderated t-stat) calculated from `genefilter`.  If we want to **adjust for adjustment variables (eg. batch effects, which includes 'lane number' in this example)**, we can see that the adjusted statistics differ even more (the line doesn't align well with y = x).

```{r}
library(limma)
design_matrix = model.matrix(~ pdata$strain)
fit_limma = lmFit(edata,design_matrix)
ebayes_limma = eBayes(fit_limma)
head(ebayes_limma$t)
plot(ebayes_limma$t[,2],-tstats_obj$statistic,col=4,
     xlab="Moderated T-stat",ylab="T-stat") # Comparing moderated and unmoderated t-stat
abline(c(0,1),col="darkgrey",lwd=3)

# Adjusting for the lane number, and the t-stat is now adjusted as well
design_adj = model.matrix(~ pdata$strain + as.factor(pdata$lane.number))
fit_limma_adj = lmFit(edata,design_adj)
ebayes_limma_adj = eBayes(fit_limma_adj)
plot(ebayes_limma_adj$t[,2],-tstats_obj$statistic,col=3,
     xlab="Moderated T-stat",ylab="T-stat")
abline(c(0,1),lwd=3,col="darkgrey")
```

For multi-group comparisons (eg. with the *primary variable* concerned here being lane number (not the poor adjustment variable this time), which is a variable with multiple levels, unlike strain with only two levels) we can also get the moderated F-stats with `topTable`. Recall that this function is originally used to display the top genes after differential analysis, and the `number` argument is by default 10 (so only show the first 10 differentially expressed genes), but now we set it to the total number of genes and we don't want it to be `sort`ed so that it's in the same order as the genes originally listed.
```{r}
design_lane = model.matrix(~ as.factor(pdata$lane.number))
fit_limma_lane = lmFit(edata,design_lane)
ebayes_limma_lane = eBayes(fit_limma_lane) 
head(ebayes_limma_lane)
top_lane = topTable(ebayes_limma_lane, coef=2:7,number=dim(edata)[1],sort.by="none")
head(top_lane)

# Also moderated
plot(top_lane$F,fstats_obj$statistic,
     xlab="Moderated F-statistic",ylab="F-statistic",col=3)
```

Likewise, we can also use `edge` to fit a model and then calculate the stat. Unlike `limma` the calculated results are unmoderated (thus exactly the same as `genefilter`, as plotted below), but `edge` also allows users to adjust for other variables. 

```{r}
library(edge)
edge_study = build_study(edata, grp = as.factor(pdata$lane.number)) # 'grp' stands for 'group'.
de_obj = lrt(edge_study)
qval = qvalueObj(de_obj)
plot(qval$stat,fstats_obj$statistic,col=4,
      xlab="F-stat from edge",ylab="F-stat from genefilter")
```

Adjusting the test statistics for lane effects:
```{r}
edge_study2 = build_study(edata, grp = as.factor(pdata$lane.number),
                        adj.var=pdata$strain)
de_obj2 = lrt(edge_study2)
qval2 = qvalueObj(de_obj2)
plot(qval2$stat,fstats_obj$statistic,col=4,
      xlab="F-stat from edge",ylab="F-stat from genefilter") # Now a bit different
```

### Permutation test 

![Shuffling labels](https://freeimghost.net/images/2025/05/04/Screenshot-2025-05-05-at-08.37.24.png)

Randomly **shuffling labels** (eg. case/control, or R/NR on the screenshot above) to **break the association between the data and the primary variables but *preserves confounder-outcome associations*.** This means that after we reshuffle the labels, recalculate the test statistic for each permutation/reshuffling, and plot the test statistic for each recalculation, we can see whether the model is incorrect (eg. we missed a confounder that would bias the model and should have adjusted for it) **if the plotted distribution for the recalculated t-stats after permutations violates the null distribution for t-stats**, i.e. not showing the t-distribution with (n - 1) degrees of freedom. So this plot can be used as a **diagnostic plot that signals problems for the model,** i.e. indicating unaccounted variables or violated assumptions. 
```{r}
# Plotting the distribution for t-stats before shuffling
hist(tstats_obj$statistic,col=2,xlim=c(-5,2))

# **Permute the sample labels using `sample()` function!!!**
set.seed(135)
strain = pdata$strain
strain0 = sample(strain)
tstats_obj0 = rowttests(edata,strain0)
# Plot again and compare the quantiles for the two distributions
hist(tstats_obj0$statistic,col=2,xlim=c(-5,2))
qqplot(tstats_obj0$statistic,tstats_obj$statistic,col=3)
abline(c(0,1))
```

### P-values, multiple testing, and corrections

The P-value: basically a hypothesis testing tool. Its distribution can be seen as concatenating two parts: for true H0, P-values should be uniformly distributed; for true Ha, P-values should peak near 0. And so they almost always go to zero with the sample size...

![P-value distribution](https://freeimghost.net/images/2025/05/04/Screenshot-2025-05-05-at-08.54.27.png)

Plotting a histogram for the calculated p-values can also be used as a diagnostic plot to reveal model problems, like the one we did for t-stats after permutation. If we get a distribution that peaks near 0 and near-uniform for the rest of the region, this probably implies that the model fits well. 

**Multiple testing**: this occurs when we perform many hypothesis tests simultaneously, eg. testing 20,000 genes for differential expressions between case/control. If each test has a 5% false positive/Type I error rate (alpha = 0.05), weâ€™d expect 1,000 false positives *by chance alone*.

To control false positives, we define three error rates and the corresponding **corrections to the significance threshold** 

- Type I error (alpha). If we simply take this into account and use the *uncorrected* p-value, the number of tests that we call 'significant' would be far more than FWER and FDR, so only this is rarely applied. 

- Family-wise error rate (FWER): the probability of **>= 1** false positives **across all tests**. 

  - Bonferroni correction: adjust significance threshold to `Type I error rate (alpha, usually just that 0.05)/total number of tests`. Super strict, applied when any false positive is unacceptable or highly undesirable (eg. clinical trials, GWAS). 

- False discovery rate (FDR): the expected proportion of false positives among all significant results. 

  - Benjamini-Hochberg correction: **ranks** p-values calculated for *each* test, and adjust significance thresholds (**q-value** is just the FDR-adjusted p-value). Apparently less strict then FWER, typically used for quantitative measurements eg. gene expression variation, where we expect to see *a relatively large number of discoveries/signals and want to quantify the percentage of them that are false positives.*
  
  - **Sometimes when we print the results of some analysis using some package, stuff like `padj` (alongside p-value) is just the FDR-adjusted p-value (or q-value)!**
  
In genomic studies, try to analyze the data once (or report all analyses), since we might otherwise run into extra false positives. 

```{r}
# Recall that the `rowttests` and `rowFtests` functions of the `genefilter` package also calculate the `p.value` alongside the test statistics. We can extract them and plot the distribution. 
fstats_obj = rowFtests(edata,as.factor(pdata$strain))
hist(fstats_obj$p.value,col=2)
# This distribution doesn't rlly align with the expected distribution for p-values we mentioned above, so we can infer that there should be other adjustment variables modeled as well. 
# Adjusting for variables isn't supported by `genefilter`, so we can use `edge` or `limma` (moderated stats) to do so.

# Using edge:
edge_study = build_study(edata, grp = pdata$strain, 
                         adj.var = as.factor(pdata$lane.number))
de_obj = lrt(edge_study)
qval = qvalueObj(de_obj)
hist(qval$pvalues,col=3)

# Using limma:
mod = model.matrix(~ pdata$strain + pdata$lane.number)
fit_limma = lmFit(edata,mod)
ebayes_limma = eBayes(fit_limma)
limma_pvals = topTable(ebayes_limma,number=dim(edata)[1])$P.Value
# Still doesn't really match the expected distribution...
hist(limma_pvals,col=4)
```

**Empirical permutation p-values**: often when we permute we want to calculate an empirical p-value. To do this we can compare each observed statistic to the permuted statistics. 

- We can either compare within a single gene (argument `pooled=FALSE` in the `empPvals` function) or pooling the permuted statistics across multiple genes (`pooled=TRUE`, the default). 
```{r}
set.seed(3333)
B = 1000
tstats_obj = rowttests(edata,pdata$strain)
tstat0 = matrix(NA,nrow=dim(edata)[1],ncol=B)
tstat = tstats_obj$statistic
strain = pdata$strain
for(i in 1:B){
  strain0 = sample(strain)
  tstat0[,i] = rowttests(edata,strain0)$statistic
}
library(qvalue)
emp_pvals = empPvals(tstat,tstat0)
hist(emp_pvals,col=2)
```

**Adjusting p-values to control false positives**: 
```{r}
fp_bonf = p.adjust(fstats_obj$p.value,method="bonferroni")
hist(fp_bonf,col=3)
quantile(fp_bonf)
sum(fp_bonf < 0.05) # None is considered as significant 

fp_bh = p.adjust(fstats_obj$p.value,method="BH")
hist(fp_bh,col=3)
quantile(fp_bh)
sum(fp_bonf < 0.05) # Again, sadly

# Using limma:
limma_pvals_adj = topTable(ebayes_limma,number=dim(edata)[1])$adj.P.Val
hist(limma_pvals_adj,col=2)
quantile(limma_pvals_adj)
sum(fp_bonf < 0.05)
```

We can also directly get the q-values (the assigned threshold when correcting for FDR). 
```{r}
qval_limma = qvalue(limma_pvals)
summary(qval_limma)
qval$pi0

# Or using edge,
qval = qvalueObj(de_obj)
summary(qval)
```


## Other Genomic Experimental Designs

### GSEA

Gene Set Enrichment Analysis. (Got a much more solid understanding of this through the TCGA practice session, niceeee)

- 'Gene set': a **predefined** set of genes (eg. from a pathway/functional category eg. KEGG or GO) *in a list of genes of interest (eg. differentially expressed (DE) genes we obtained in an experiment)*.

- 'Enrichment': "are genes in this predefined set more frequently observed in my results *than expected by random chance?*" Returns the gene **sets** or pathways. 

  - Quantified by comparing the observed overlap between the gene set and DEGs to a null distribution (random expectation). Common metrics include (corrected) p-values and Enrichment Score (ES).
  
  - Permutation tests are applied: randomly shuffling labels of the phenotype data and then recalculating ES. 
  
Here we'll use the `goseq` package for GSEA. It is specifically designed for **RNA-seq data** and is remarkable in being able to correct for **length bias** by *weighting genes based on their length*.

- **In RNA-seq, longer genes are more likely to be detected as differentially expressed.** This is due to: 1. longer genes -> more transcript fragments (since these fragmented short reads are typically all 100-150bp) -> more reads mapped; 2. more reads -> lower variance in count estimates (reduced SE due to 'large numbers') -> *higher likelihood of passing significance thresholds*.

  
```{r}
library(goseq)
library(DESeq2)

# Here we load the example from the `goseq` package. 
temp_data =read.table(system.file("extdata","Li_sum.txt",
                                     package="goseq"),sep="\t",
                                     header=TRUE,
                                     stringsAsFactors=FALSE)
```

```{r}
head(temp_data)
# We process the data: the first column is just the gene IDs, so we set it as the row name and remove that column.
edata = temp_data[,-1]
rownames(edata) = temp_data[,1]
# Filter the data
edata = edata[rowMeans(edata) > 5,]

# We manually set the group variable up and create a pdata with that variable
grp=factor(rep(c("Control","Treated"),times=c(4,3)))
pdata  = data.frame(grp)

# And then (exactly the same as what we did in Course 5  when learning how to run a differential analysis~~~~) we'll pass the data to a DESeq data container (the DESeqDataSet thingy), fit the model, and obtain the results.
setOldClass("ExpData") # to circumvent the very recent error... the error wasn't there when I was still taking the course but it can't properly execute and knit anymore in May
de = DESeqDataSetFromMatrix(edata, pdata, ~grp)
de_fit = DESeq(de)
de_results = results(de_fit)


# So the `padj` column is just the p-values corrected for FDR. And then we'll filter the genes to only keep those that pass the threshold to be differentially expressed. 
genes = as.integer(de_results$padj < 0.05)
names(genes) = rownames(edata) # Identifying the genes using the ENSEMBL IDs. Recall in Course 5 we mentioned that the results for a DESeq2-performed differential analysis aren't ordered; this is actually quite nice here since we want to retain the order for these genes and then apply their names >w<
not_na = !is.na(genes) 
genes = genes[not_na] 
```
```{r}
# Preview some of the automatically supported genomes
#head(supportedGenomes())
#head(supportedGeneIDs())

# As described earlier, for `goseq` (which corrects for RNA-seq length bias) we need to set up a **weighting** function for all the genes in that genome. 
# `nullp` function of `goseq` calculates a 'Probability Weighting Function` for a set of genes based on a given set of biased data, usually gene length.
pwf=nullp(genes,"hg19","ensGene")
head(pwf)
```
```{r}
# Now we can finally run the GSEA. We apply the `goseq` function to the probability weighting function we've obtained for these genes, the genome we're looking at (hg19), and tell it that we identify genes using their ENSEMBL IDs.
# And then `goseq` will go and fetch the GO annotations from the web.

library(org.Hs.eg.db) # This is a Bioconductor package that provides genome-wide annotations for humans.
GO.wall=goseq(pwf,"hg19","ensGene") # We can also limit this to a particular GO category (recall that there are molecular function (MF), cellular component (CC), and biological process (BP) in GO) by setting the argument eg. test.cats=c("GO:MF").
head(GO.wall)
```

### eQTL

Expression Quantitative Trait Loci or eQTL is one of the most common integrative analyses in genomics. It tries to identify variations in DNA (eg. SNPs) that correlate with variations in the expression levels of the corresponding RNA. So we can think of it as *performing a gene expression microarray analysis for every single SNP*. If the expression differences pass the significance threshold we'll classify it as an eQTL.

We can use the `MatrixETQL` package for illustration. We have to load three files: SNP data, expression data, and covariate data (everything that you might want to *adjust for*). eQTL truly is **combing different genomic data types**. 

```{r}
library(MatrixEQTL)
# Download the data
base.dir = find.package("MatrixEQTL")
SNP_file_name = paste(base.dir, "/data/SNP.txt", sep="");
expression_file_name = paste(base.dir, "/data/GE.txt", sep="")
covariates_file_name = paste(base.dir, "/data/Covariates.txt", sep="")
output_file_name = tempfile()

# Load it and get a preview for the first gene
expr = read.table(expression_file_name,sep="\t",
                  header=T,row.names=1)
expr[1,]

snps = read.table(SNP_file_name,sep="\t",
                  header=T,row.names=1)
snps[1,]

cvrt = read.table(covariates_file_name,sep="\t",
                  header=T,row.names=1)
# The simplest eQTL analysis just computes linear regression models for each SNP/gene pair.
e1 = as.numeric(expr[1,]) # Extract the info we just previewed to fit a linear model as variables
s1 = as.numeric(snps[1,])
lm1 = lm(e1 ~ s1) 
# tidy(lm1) We can see that the p-value is too big so it's prob not so correlated
plot(e1 ~ jitter(s1),
     col=(s1+1),xaxt="n",xlab="Genotype",ylab="Expression")
axis(1,at=c(0:2),labels=c("AA","Aa","aa")) # We have assumed an 'additive' model for the genotype rather than 'dominant' (after all, it's SNP!!)
lines(lm1$fitted ~ s1,type="b",pch=15,col="darkgrey")
```

The simplest eQTL analysis just computes **linear regression models for each SNP/gene pair**. We can fit many eQTL models with `MatrixEQTL` (just like we can fit only one gene with the regular `lm` function but we'll use the `limma` package to fit many linear models for many genes or otherwise it's gonna take a long~~ time~~).

```{r}
# Set up parameters
pvOutputThreshold = 1e-2 # it's basically going to throw away everything above the threshold, which will save a lot of computational time and space
errorCovariance = numeric()
useModel = modelLINEAR # tell it to just use the standard 'additive' model

# Set up the files for MatrixEQTL
snps = SlicedData$new()
snps$fileDelimiter = "\t"     # the TAB character
snps$fileOmitCharacters = "NA" # denote missing values;
snps$fileSkipRows = 1          # one row of column labels
snps$fileSkipColumns = 1       # one column of row labels
snps$fileSliceSize = 2000     # It's going to break the files up into chunks to compute more easily (in this case break the file in chunks of 2000 rows); the bigger the chunks the faster it can compute, but the slower it takes to load more data in, so there's a balance/compromise there
snps$LoadFile( SNP_file_name )

gene = SlicedData$new()
gene$fileDelimiter = "\t"      
gene$fileOmitCharacters = "NA" 
gene$fileSkipRows = 1          
gene$fileSkipColumns = 1      
gene$fileSliceSize = 2000      
gene$LoadFile(expression_file_name)

cvrt = SlicedData$new()

# Pass the parameters and the data objects to the function 
me = Matrix_eQTL_engine(
    snps = snps,
    gene = gene,
    cvrt = cvrt,
    output_file_name = NULL,
    pvOutputThreshold = pvOutputThreshold,
    useModel = useModel, 
    errorCovariance = errorCovariance, 
    verbose = TRUE,
    pvalue.hist = TRUE,
    min.pv.by.genesnp = FALSE,
    noFDRsaveMemory = FALSE)
```
```{r}
plot(me) # plot all the p-values from the tests; when running the function we set the argument `pvalue.hist` to be TRUE.
# Check the number and type of eQTLs
me$all$neqtls # Only one passed the significant threshold we set
me$all$eqtls
```
### Statistical inference vs. prediction 

Both of these have their 'central dogmas' to keep in mind and are quite different. The latter is very similar to ML that we've covered before.

## The end

AND BAM we made it!!!!!

Hopefully this kaomoji will work...
```
             /\_____/\
          >| Ë¶ â€¢ á´› â€¢ Ë¶ |< 
           /   ð‡Œâ˜†ð‡‹     \
      KEEP UP the good work~~
```


