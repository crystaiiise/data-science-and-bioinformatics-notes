{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9327612a-da9c-4c27-9569-c23c0967e0cf",
   "metadata": {},
   "source": [
    "**Ch05-13: Pandas入门及数据预处理！！**\n",
    "\n",
    "Source: \n",
    "[数据分析实战 45 讲](https://time.geekbang.org/column/intro/100021701?tab=intro)\n",
    "\n",
    "---\n",
    "\n",
    "## Series与DataFrame\n",
    "\n",
    "Series是个定长的字典序列，存储的时候相当于两个 ndarray，这也是和字典（元素个数不固定）最大的不同。Series有两个基本属性：index和values。可以`Series(data=[],index=[])`创建（可不指定index，即平平无奇数字索引），也可以采用字典的方式`Series({})`创建。\n",
    "\n",
    "可以将DataFrame看成是由相同索引的Series**按列叠起来**组成的字典类型，所以**此时字典的键是对应列索引**的，而**行索引由Series自己的index决定**（见下面）。\n",
    "\n",
    "- 也请注意“由相同索引的Series”这个限定条件，因为如果索引不同的话会像底下df2那样子。\n",
    "\n",
    "pandas允许直接从xlsx和csv等文件中读入数据（eg. `pd.read_csv()`，也可以写入到这些文件中。\n",
    "\n",
    "### DataFrame访问\n",
    "\n",
    "- `DataFrame.loc['row','col']`/`DataFrame.iloc[row_index,col_index]`属于**单步赋值**；`df['col']['row']`属于**链式赋值**，赋值后会自动生成副本，不是修改原数据。\n",
    "\n",
    "    - 一定一定注意！！！对于链式赋值是先列后行！！！！！相反的！！！！\n",
    "\n",
    "- 链式赋值时不可以直接用`[:]`进行切片，想用冒号必须得单步赋值，eg. `df.iloc[1:3]`或`df.loc[:, 'B':'D']`。\n",
    "\n",
    "- 遍历df的时候用列索引组成的list最方便。\n",
    "\n",
    "## 函数/方法\n",
    "\n",
    "- 使用`Series.method()`、`DataFrame.method()`以及`pd.function()`时（除非`inplace=True`）会产生新副本，所以想修改原数据的话要记得assign back。\n",
    "\n",
    "- Pandas和NumPy一样，都有常用的统计函数，并且如果遇到空值NaN会自动排除。`DataFrame.describe()`可以一次性输出很多统计值！\n",
    "\n",
    "- 区分一下这三种函数（底下还有例子）。它们的效果给人一种numpy ufunc的感觉（吗），不用for循环逐元素遍历。\n",
    "\n",
    "    - `.apply(func)`: **more versatile; flexible output shape**. Allows for axis control (row-wise by `axis=1` or column-wise by `axis=0`) when applied on a DataFrame.\n",
    "\n",
    "    - `.map(func)`: simple **element-wise** operations. `DataFrame.map` is renamed from `DataFrame.applymap`; when using this, the function applied *must return a single value from a single value* (so aggregate functions not permitted).\n",
    "\n",
    "    - `.transform(func)`: **often used with `groupby()`** for *aggregation functions*, but strictly ensures the output shape matches the input.\n",
    " \n",
    "    - `func`不用后面的括号。\n",
    "\n",
    "### DataFrame.method()中奇怪的axis\n",
    "\n",
    "pandas里面指定某方向真的好奇怪，有些跟numpy是相反的有些好像又不是，，，\n",
    "\n",
    "* “`axis=0` (default): refers to operations **along rows**, meaning it applies column-wise (in the **vertical** direction). Note that for *operation methods* like `DataFrame.drop()` and `DataFrame.rename()` they're exerted **on rows**, due to the aforementioned *\"along rows\"*. \n",
    "\n",
    "### pandas与SQL\n",
    "\n",
    "- 数据表合并：`pd.merge()`函数的`how=`参数分'inner'/'left'/'right'/'outer'，拼接方式等同于SQL中的INNER/LEFT/RIGHT/OUTER JOIN，而且也是用`on=`参数指定匹配依据的列。\n",
    "\n",
    "- pandasql包：在python中直接使用SQL queries操作DataFrame。pandasql中的主要函数是`sqldf()`，它接收两个参数：一个SQL语句，还有一组环境变量`globals()`或`locals()`。使用匿名函数：\n",
    "  \n",
    "```Python\n",
    "pysqldf = lambda sql: sqldf(sql, globals())\n",
    "sql = \"SELECT * FROM df1 WHERE name ='_'\"\n",
    "print(pysqldf(sql))\n",
    "```\n",
    "---\n",
    "\n",
    "# pandas与数据清洗\n",
    "\n",
    "有时候先用`DataFrame.astype()`把格式转成str类型是为了方便对数据进行操作，因为有好多好用的`Series.str.method()`，比如可以用`strip()`删除数据间的空格或其他指定字符、大小写转换等。\n",
    "\n",
    "**数据清洗可总结为四个关键点 “完全合一”：**\n",
    "\n",
    "1. **完**整性：是否存在空值，字段是否完整。`Series.fillna()`对**某字段的缺失值**进行填充，`DataFrame.dropna(how='all')`删除全部**空行**。\n",
    "\n",
    "```Python\n",
    "# 用众数填充缺失字段\n",
    "data = {'A': [1, 2, 2, np.nan, 3],'B': [np.nan, 'x', 'y', 'x', 'x']}\n",
    "df = pd.DataFrame(data)\n",
    "for column in df.columns:  # 这样子遍历好用\n",
    "    mode_value = df[column].mode()[0]  # 获取众数，注意对于数值类型还是非数值类型都能用！！\n",
    "    df[column] = df[column].fillna(mode_value)  \n",
    "```\n",
    "\n",
    "2. **全**面性：观察某列数值，瞪眼法或者通过几个统计值（eg. 均值/最值）判断该列是否有问题，比如**列数据的单位不统一**。\n",
    "\n",
    "```Python\n",
    "# 单位不统一时，将磅（lbs）转化为千克（kg）：\n",
    "rows_with_lbs = df['weight'].str.contains('lbs').fillna(False) # 获取weight列中单位为lbs的数据\n",
    "print(df[rows_with_lbs])\n",
    "for i,lbs_row in df[rows_with_lbs].iterrows(): # DataFrame.iterrows还会返回行索引！\n",
    "  # 截取从头开始到倒数第三个字符之前，即去掉lbs。再将lbs转换为kg, 2.2lbs=1kg\n",
    "  weight = int(float(lbs_row['weight'][:-3])/2.2)\n",
    "  df.at[i,'weight'] = '{}kgs'.format(weight) \n",
    "```\n",
    "\n",
    "3. **合**法性：数据的类型、内容、大小是否合法，比如是否存在非ASCII字符、年龄超过150岁等。\n",
    "\n",
    "```Python\n",
    "# 删除非 ASCII 字符\n",
    "df['first_name'] = df['first_name'].replace({r'[^\\x00-\\x7F]+':''}, regex=True)\n",
    "df['last_name'] = df['last_name'].replace({r'[^\\x00-\\x7F]+':''}, regex=True)\n",
    "```\n",
    "\n",
    "4. **唯**一性：数据是否存在重复记录；行数据、列数据都需要是唯一的，列的话可以使用`Series.str.split`切分并`DataFrame.drop('col', axis=1)`删除原数据列，行的话就是`DataFrame.drop_duplicates('col')`啦。\n",
    "\n",
    "```Python\n",
    "# 切分名字，删除源数据列\n",
    "df[['first_name','last_name']] = df['name'].str.split(expand=True)\n",
    "df = df.drop('name', axis=1)\n",
    "```\n",
    "---\n",
    "\n",
    "# 数据规范化\n",
    "\n",
    "## sklearn.preprocessing\n",
    "\n",
    "**一条极度personalized的reminder：scaler千万别再拼错成scalar我都服了怎么可以这么笨**\n",
    "\n",
    "从贝叶斯分类器那里复制过来：\n",
    "\n",
    "`transform()`和`fit_transform()`二者的功能都是对数据进行某种统一处理（比如标准化，将数据缩放(映射)到某个固定区间等等）。\n",
    "\n",
    "- `fit_transform(trainData)`对训练数据先**拟合**fit，找到该部分的整体指标，如均值、方差等，然后对该trainData进行**转换**transform，从而实现数据的标准化、归一化等等。\n",
    "\n",
    "- 根据对之前trainData进行fit后的整体指标！！对剩余的数据（testData）使用同样的均值、方差等指标进行转换`transform(testData)`，**从而保证train、test处理方式相同**！！！！\n",
    "\n",
    "### 数据规范化的几种方法\n",
    "\n",
    "最底下是代码示例！\n",
    "\n",
    "1. **Min-max规范化**：把原始数据映射到指定空间`[min, max]`，默认为`[0,1]`。\n",
    "\n",
    "2. **Z-score规范化**：没错就是统计里面那个test statistic！！（原数值 - 均值）/ SD，但Z-score的不足就在于它除了用于比较外结果没什么实际意义。 sklearn中`preprocessing.scale()`可以直接给数据这样子规范化，`preprocessing.StandardScalar()`类（注意命名！）功能相同，但这个需要先实例化创建一个对象再用到上述的`fit_transform`。\n",
    "\n",
    "3. **小数定标规范化**：通过移动小数点的位置来进行规范化，小数点移动多少位取决于该属性取值中的最大绝对值，比如属性A的取值范围是-999到88，那么最大绝对值为999，小数点就会移动3位，即新数值 = 原数值 /1000，即A的取值范围被规范化为-0.999到0.088。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac7d8cb-b543-477c-a4e1-3ba9d377b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未指定索引名:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n",
      "e    5\n",
      "f    6\n",
      "g    7\n",
      "h    8\n",
      "dtype: int64\n",
      "   Col_1  Col_2\n",
      "0      1      0\n",
      "1      2      1\n",
      "2      3      2\n",
      "3      4      3\n",
      "   Col_1  Col_2\n",
      "0    1.0    NaN\n",
      "1    2.0    NaN\n",
      "2    3.0    NaN\n",
      "3    4.0    NaN\n",
      "a    NaN    1.0\n",
      "b    NaN    2.0\n",
      "c    NaN    3.0\n",
      "d    NaN    4.0 \n",
      "所以果然Series得索引相同才能叠一起\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating Series\n",
    "a1 = pd.Series([1,2,3,4])\n",
    "a2 = pd.Series(data=[1,2,3,4], index=['a','b','c','d'])\n",
    "a3 = pd.Series({'e':5,'f':6,'g':7,'h':8}) # 也可以采用字典的方式来创建 Series\n",
    "print(\"未指定索引名:\\n\",a1)\n",
    "print(a2)\n",
    "print(a3)\n",
    "\n",
    "# Creating a df by passing a dict (stacked as columns!!!)\n",
    "df1 = pd.DataFrame({'Col_1':a1, # 毕竟a1是未指定索引名的嘛\n",
    "                    'Col_2':range(4)})\n",
    "print(df1)\n",
    "print(pd.DataFrame({'Col_1':a1,'Col_2':a2}),\"\\n所以果然Series得索引相同才能叠一起\")                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "816f642d-cf82-41ce-b01b-cb76b052c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     4\n",
      "B    12\n",
      "dtype: int64 Flexible output shape\n",
      "\n",
      " 0      a\n",
      "1      a\n",
      "2    NaN\n",
      "Name: A, dtype: object\n",
      "\n",
      "    B\n",
      "0  7\n",
      "1  7\n",
      "2  5 Output shape strictly matches input shape, so '7' (grouped by 'A') repeated twice\n"
     ]
    }
   ],
   "source": [
    "# apply(), map(), transform()\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 1, 2], 'B': [3, 4, 5]})\n",
    "\n",
    "df_apply = df.apply(sum, axis=0)\n",
    "df_map_dict = df['A'].map({1:'a',4:'b'}) # mapping using a dict\n",
    "df_transform = df.groupby('A').transform(\"sum\")\n",
    "print(df_apply, \"Flexible output shape\")\n",
    "print(\"\\n\",df_map_dict)\n",
    "print(\"\\n\",df_transform,\"Output shape strictly matches input shape, so '7' (grouped by 'A') repeated twice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f41e3c97-54a8-48b3-9a62-2428a9c2b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.66666667]\n",
      " [1.         1.         1.        ]\n",
      " [0.         1.         0.        ]]\n",
      "[[-0.70710678 -1.41421356  0.26726124]\n",
      " [ 1.41421356  0.70710678  1.06904497]\n",
      " [-0.70710678  0.70710678 -1.33630621]]\n",
      "[[ 0.  -0.3  0.1]\n",
      " [ 0.3  0.1  0.2]\n",
      " [ 0.   0.1 -0.1]]\n"
     ]
    }
   ],
   "source": [
    "# 数据规范化！！！\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[ 0., -3.,  1.],\n",
    "              [ 3.,  1.,  2.],\n",
    "              [ 0.,  1., -1.]])\n",
    "\n",
    "# Min-max规范化，默认映射到[0,1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "minmax_x = min_max_scaler.fit_transform(x)\n",
    "print(minmax_x)\n",
    "\n",
    "# Z-Score规范化\n",
    "scaled_x = preprocessing.scale(x)\n",
    "print(scaled_x)\n",
    "\n",
    "# 小数定标规范化\n",
    "j = np.ceil(np.log10(np.max(abs(x))))\n",
    "scaled_x2 = x/(10**j)\n",
    "print(scaled_x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
